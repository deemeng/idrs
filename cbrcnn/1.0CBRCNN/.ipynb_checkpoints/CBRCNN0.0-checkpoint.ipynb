{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c49fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "# import hyperparameters\n",
    "from cbrcnn_hyperparams import *\n",
    "# from model import BRNN\n",
    "# from utils import load_dataset, get_num_class\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# processing bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'{model_name}board_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28181e2",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbea74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.setLevel(logging.INFO)\n",
    "# logging.basicConfig(level=logging.NOTSET)\n",
    "logging.basicConfig(filename=log_name+'_test', \n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %P',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db91d1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.warning('Device: ' + device.type)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc9627",
   "metadata": {},
   "source": [
    "### Test hyperpramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9ccd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "train_fpath = root_path + '/data/train'\n",
    "test_fpath = root_path + '/data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cf1f5",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3be1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fpath):\n",
    "    '''\n",
    "    params:\n",
    "        fpath - path to fasta file, training or test\n",
    "                ***The format of the sets:\n",
    "\n",
    "                The first two lines are a global header:\n",
    "                total_number_of_records\n",
    "                input_size number_of_classes\n",
    "\n",
    "                total_number_of_records is simply the number of proteins in the set,\n",
    "                input_size is how many numbers are used to represent one amino acid (21\n",
    "                or 22, probably, in your case) and number_of_classes is the number of\n",
    "                classes...\n",
    "\n",
    "                After that you have the proteins, 5 lines each:\n",
    "\n",
    "                line 1: name of the protein\n",
    "                line 2: number of amino acids in the protein\n",
    "                line 3: input\n",
    "                line 4: targets\n",
    "                line 5: empty\n",
    "\n",
    "                You can use any name you want so long as it's unique, a single word, and\n",
    "                not outrageously long.\n",
    "\n",
    "                The input should be a single long list of the numbers representing the\n",
    "                amino acids in the protein. If you use, say, 21 numbers per amino acid,\n",
    "                and the protein is 100 amino acids long, the input line will contain\n",
    "                2100 numbers, with the first 21 being the representation of the first\n",
    "                amino acid in the protein, the following 21 the representation of the\n",
    "                second, etc.\n",
    "                For the moment (before we use alignments) the representation of an amino\n",
    "                acid will be a one-hot encoding, e.g.:\n",
    "\n",
    "                A     -> 1 0 0 0 ..... 0 0\n",
    "                C     -> 0 1 0 0 ..... 0 0\n",
    "                ...\n",
    "                Y     -> 0 0 0 0 ..... 1 0\n",
    "                other -> 0 0 0 0 ..... 0 1\n",
    "\n",
    "                where \"other\" is unknown or weird amino acid (X, B, J, O, U, Z)\n",
    "\n",
    "                The line containing the targets is a list of integers representing the\n",
    "                classes of the amino acids. There are as many integers as there are\n",
    "                amino acids in the protein. You can choose whatever integers you want,\n",
    "                but it's probably simplest to have something like class1=0, class2=1,\n",
    "                class3=2, etc..\n",
    "\n",
    "                (notice that in the sample sets in the directory you have a more\n",
    "                complicated representation of the inputs, where there are a lot of\n",
    "                floating point numbers rather than just 0 and 1, and that's because\n",
    "                those inputs are frequency profiles from MSA - so you can see how the\n",
    "                code works for both kinds of inputs)\n",
    "                \n",
    "    returns:\n",
    "        p_data - list[data_tensor, target_tensor]\n",
    "        p_lens - list, protein length\n",
    "    \n",
    "    Note: \n",
    "        - the reason not using tensor to save protein Sequences and Targets is we have varying length sequences! \n",
    "        - solve this problem we could consider pading. But our dataset lens range from about 20 to 10,000. \n",
    "            Thus, padding maybe not a good idea here.\n",
    "        - to solve variance sequences problem, we can use pad_sequence, pack_padded_sequence & \n",
    "    '''\n",
    "    num_protein = 0\n",
    "    num_i = 0\n",
    "    num_o = 0\n",
    "\n",
    "    # p_names = []\n",
    "    p_lens = []\n",
    "    # p_seqs = []\n",
    "    # p_anns = []\n",
    "    p_data = []\n",
    "    with open(fpath) as fp:\n",
    "        num_protein = int(fp.readline())\n",
    "        num_io = fp.readline().split(' ')\n",
    "        num_i = int(num_io[0])\n",
    "        num_o = int(num_io[0])\n",
    "\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            # p_name = line[:-1]\n",
    "            p_len = int(fp.readline())\n",
    "            p_sequence = torch.tensor([int(x) for x in fp.readline().split(' ')], \n",
    "                                      dtype=torch.float32).reshape(-1, 21)\n",
    "            p_annotation = torch.tensor([[int(x)] for x in fp.readline().split(' ')], dtype=torch.float32)\n",
    "            # skip empty\n",
    "            next(fp)\n",
    "            # p_names.append(p_name)\n",
    "            p_lens.append(p_len)\n",
    "            # p_seqs.append(p_sequence)\n",
    "            # p_anns.append(p_annotation)\n",
    "            p_data.append([p_sequence, p_annotation])\n",
    "            line = fp.readline()   \n",
    "    return p_data, p_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fpath, transform=None):\n",
    "        self.p_data, self.p_lens = load_dataset(fpath)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.p_lens)\n",
    "    \n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        # self.p_data[i][0], sequence;  self.p_data[i][1], label\n",
    "        return self.p_data[i][0], self.p_data[i][1]\n",
    "    def numAAs(self) -> int:\n",
    "        return sum(self.p_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43277d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_packed_collate(batch):\n",
    "    \"\"\"Puts data, and lengths into a packed_padded_sequence then returns\n",
    "       the packed_padded_sequence and the labels. Set use_lengths to True\n",
    "       to use this collate function.\n",
    "       Args:\n",
    "         batch: (list of tuples) [(sequence, target)].\n",
    "             sequence is a FloatTensor\n",
    "             target has the same variable length with sequence\n",
    "       Output:\n",
    "         packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "         labels: (Tensor), labels from the file names of the wav.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(batch) == 1:\n",
    "        seqs, labels = [batch[0][0]], [batch[0][1]]\n",
    "        lengths = [seqs[0].size(0)]\n",
    "        \n",
    "    if len(batch) > 1:\n",
    "        # get data and sorted by the length of sequence\n",
    "        seqs, labels, lengths = zip(*[(a, b, a.size(0)) for (a,b) in sorted(batch, key=lambda x: x[0].size(0), reverse=True)])\n",
    "    seqs = pad_sequence(seqs, batch_first=True)\n",
    "    labels = pad_sequence(labels, batch_first=True)\n",
    "    packed_seqs = pack_padded_sequence(seqs, lengths, batch_first=True)\n",
    "    packed_labels = pack_padded_sequence(labels, lengths, batch_first=True)\n",
    "    \n",
    "    return packed_seqs, packed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b463f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocPlot(train_label, train_probs, val_label, val_probs):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    t_fpr, t_tpr, t_thresholds = roc_curve(train_label, train_probs)\n",
    "    t_roc_auc = auc(t_fpr, t_tpr)\n",
    "    v_fpr, v_tpr, v_thresholds = roc_curve(val_label, val_probs)\n",
    "    v_roc_auc = auc(v_fpr, v_tpr)\n",
    "    \n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        t_fpr,\n",
    "        t_tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"Training (area = %0.2f)\" % t_roc_auc,\n",
    "    )\n",
    "    \n",
    "    plt.plot(\n",
    "        v_fpr,\n",
    "        v_tpr,\n",
    "        color=\"darkgreen\",\n",
    "        lw=lw,\n",
    "        label=\"Val (area = %0.2f)\" % v_roc_auc,\n",
    "    )\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(model_name+\": Train & Val ROC curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e6e5e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed1c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!\n",
    "# file need extra one empty line\n",
    "# !!!!\n",
    "logging.warning('Loading training file ...')\n",
    "train_ds = ProteinDataset(train_fpath)\n",
    "logging.warning('Loading test file ...')\n",
    "test_ds = ProteinDataset(test_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0756d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.p_data[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55acabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "# using pad_packed_collate to deal with padding\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, num_workers = 72, shuffle=True, collate_fn=pad_packed_collate)\n",
    "test_dl = DataLoader(test_ds, batch_size = batch_size, num_workers = 72, shuffle=False, collate_fn=pad_packed_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660feabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning('Training set: ' + str(len(train_ds.p_lens)))\n",
    "logging.warning('Test set:     ' + str(len(test_ds.p_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf19e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, label) in enumerate(train_dl):\n",
    "#     print(data.batch_sizes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba5834",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c463250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CBRCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropP = 0):\n",
    "        super(CBRCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                         bidirectional=True)\n",
    "        # self.fc = nn.Linear(hidden_size*2, 1)\n",
    "        \n",
    "        self.conv11 = nn.Conv2d(in_channels=1, out_channels=3, \n",
    "                               kernel_size=(7, hidden_size*2),\n",
    "                              stride = 1, padding=(3, 0))\n",
    "        \n",
    "#         self.conv12 = nn.Conv2d(in_channels=7, out_channels=1, \n",
    "#                                kernel_size=(3, 3),\n",
    "#                               stride = 1, padding=(1, 1))\n",
    "        \n",
    "        self.conv12 = nn.Conv1d(in_channels=3, out_channels=1,\n",
    "                              kernel_size=1, stride=1, \n",
    "                               padding=0)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.drop = nn.Dropout(p = dropP)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.batch_sizes[0], self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.batch_sizes[0], self.hidden_size).to(device)\n",
    "        # Forward Prop\n",
    "        # out, (hn, cn) = self.lstm(x,  (h0, c0))\n",
    "        # out, _ = self.lstm(x,  (h0, c0))\n",
    "        packed_out, (hn, cn) = self.lstm1(x,  (h0, c0))\n",
    "        cx, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        # all training example, last hidden state, all \n",
    "        # it is not last hidden state, it is the last batch\n",
    "        # print('out.squeeze() ', out.squeeze().size())\n",
    "        # out = self.fc(out)\n",
    "        \n",
    "        cx = torch.tanh(self.conv11(torch.unsqueeze(cx, 1)))\n",
    "        \n",
    "        out = self.conv12(cx.squeeze(3)) \n",
    "        out = self.drop(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def train_batch(self, train_loader, optimizer, criterion):\n",
    "        # set training state to model\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        \n",
    "        with tqdm(total=len(train_loader), position=0) as progress_bar:\n",
    "            for batch_idx, (data, label) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self(data)\n",
    "                output = output.squeeze().unsqueeze(2)\n",
    "                \n",
    "                label, _ = pad_packed_sequence(label, batch_first=True)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "    def val_batch(self, val_data, criterion): \n",
    "        # set evaluation state to the model\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        losses = []\n",
    "        \n",
    "        class_probs = []\n",
    "        class_label = []\n",
    "        \n",
    "        # no gradient needed\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_data):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                # forward\n",
    "                scores = self(data)\n",
    "                scores = scores.squeeze().unsqueeze(2)\n",
    "                \n",
    "                target, _ = pad_packed_sequence(target, batch_first=True)\n",
    "                \n",
    "                loss = criterion(scores, target)\n",
    "                # ERROR\n",
    "                losses.append(loss.cpu()) # loss for each batch\n",
    "                # save for ploting curve\n",
    "                class_probs.append(scores.squeeze(-1).cpu())\n",
    "                class_label.append(target.cpu())\n",
    "                \n",
    "        # overall loss\n",
    "        loss = np.mean(losses)\n",
    "        return loss, class_probs, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f68eb",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "675c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = CBRCNN(input_size, hidden_size, num_layers, num_classes, dropP)\n",
    "# propogation of two classes\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43d059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f109dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████▌                | 3/4 [00:04<00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 3, 378, 1])\n",
      "x:  torch.Size([2, 3, 559, 1])\n",
      "x:  torch.Size([2, 3, 267, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 3, 817, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 3, 378, 1])\n",
      "x:  torch.Size([2, 3, 267, 1])\n",
      "x:  torch.Size([2, 3, 817, 1])\n",
      "x:  torch.Size([2, 3, 559, 1])\n",
      "x:  torch.Size([2, 3, 640, 1])\n",
      "Training: Loss:\n",
      "0.56105524\n",
      "VAL: Loss:\n",
      "0.5817804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/4 [00:00<?, ?it/s]/home/qinqin/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 50%|█████████████████████████████████                                 | 2/4 [00:04<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 3, 817, 1])\n",
      "x:  torch.Size([2, 3, 559, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 3, 378, 1])\n",
      "x:  torch.Size([2, 3, 208, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.12s/it]\n",
      "Exception ignored in: <function _releaseLock at 0x7fe17f546e60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qinqin/anaconda3/envs/py37/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 162599, 162600, 162601, 162602, 162603, 162604, 162605, 162606, 162607, 162608, 162609, 162610, 162611, 162612, 162613, 162614, 162615, 162616, 162617, 162618, 162619) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_140961/1660920800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# acc & loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_class_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_class_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_140961/442316299.py\u001b[0m in \u001b[0;36mval_batch\u001b[0;34m(self, val_data, criterion)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# no gradient needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 162599, 162600, 162601, 162602, 162603, 162604, 162605, 162606, 162607, 162608, 162609, 162610, 162611, 162612, 162613, 162614, 162615, 162616, 162617, 162618, 162619) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.warning('*********************************')\n",
    "    logging.warning('epoch: ' + str(epoch))\n",
    "    logging.warning('*********************************')\n",
    "    ################\n",
    "    # 3.1. Training\n",
    "    ################\n",
    "    logging.warning('1. TRAINING:')\n",
    "    # plot pr and roc curve or not\n",
    "    plot_pr_roc = (epoch % plot_nEpoch == 0)\n",
    "\n",
    "    # training\n",
    "    model.train_batch(train_dl, optimizer, criterion)\n",
    "    \n",
    "    # acc & loss\n",
    "    train_loss, t_class_probs, t_class_label = model.val_batch(train_dl, criterion)\n",
    "    val_loss, v_class_probs, v_class_label = model.val_batch(test_dl, criterion)\n",
    "    \n",
    "    # val_accs.append(val_acc)\n",
    "    \n",
    "    print('Training: Loss:')\n",
    "    print(train_loss)\n",
    "    \n",
    "    print('VAL: Loss:')\n",
    "    print(val_loss)\n",
    "    \n",
    "    logging.warning('Training:')\n",
    "    logging.warning(f'Loss: {train_loss}')\n",
    "\n",
    "    logging.warning('Validation:')\n",
    "    logging.warning(f'Loss: {val_loss}')\n",
    "    \n",
    "    ##\n",
    "    # for tensorboard plots\n",
    "    ##\n",
    "    writer.add_scalars(\"TRAIN & VAL Loss\", {'TRAIN': train_loss, \n",
    "                                           'VAL': val_loss}, epoch)\n",
    "    \n",
    "    train_probs = torch.cat([batch.reshape(-1) for batch in t_class_probs])\n",
    "    train_label = torch.cat([lab.reshape(-1) for lab in t_class_label])\n",
    "    \n",
    "    val_probs = torch.cat([batch.reshape(-1) for batch in v_class_probs])\n",
    "    val_label = torch.cat([lab.reshape(-1) for lab in v_class_label])\n",
    "    \n",
    "    writer.add_scalars(\"AUC Score\", {'TRAIN': roc_auc_score(train_label, train_probs, average=None),\n",
    "                                    'VAL': roc_auc_score(val_label, val_probs, average=None)}, epoch)\n",
    "    \n",
    "    ##\n",
    "    # PR-curve & ROC-curve\n",
    "    ##\n",
    "    if plot_pr_roc:\n",
    "        writer.add_pr_curve(f'TRAIN: pr_curve e{epoch}', train_label, train_probs, 0)\n",
    "        writer.add_pr_curve(f'VAL: pr_curve e{epoch}', val_label, val_probs, 0)\n",
    "\n",
    "        roc_fig = rocPlot(train_label, train_probs, val_label, val_probs)\n",
    "        writer.add_figure(f'Train vs VAL: roc_curve e{epoch}', roc_fig)\n",
    "    ##\n",
    "    # Save model every m epochs\n",
    "    ##\n",
    "    if epoch % checkpoint_m == 0:\n",
    "        cPATH = f\"checkpoint/{model_name}_{epoch}.pth\"\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    }, cPATH)\n",
    "        \n",
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                 num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate} \\n \")\n",
    "                # best_val_epoch: {int(np.argmax(val_accs)+1)}\") # the best val epoch\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46641f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(x, 0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "888fe787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cde796d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRNN(\n",
      "  (lstm): LSTM(21, 24, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=48, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dd3b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 2000, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([2000, 48])\n",
      "out final:  torch.Size([2000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BRNN                                     [2000, 1]                 --\n",
       "├─LSTM: 1-1                              [1, 2000, 48]             23,232\n",
       "├─Linear: 1-2                            [2000, 1]                 49\n",
       "├─Sigmoid: 1-3                           [2000, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 23,281\n",
       "Trainable params: 23,281\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 46.56\n",
       "==========================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 0.78\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 1.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "seq_len = 2000\n",
    "summary(model, input_size=(1, seq_len, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e1a3",
   "metadata": {},
   "source": [
    "## Test pad_sequence & pack_padded_sequence & pad_packed_sequence\n",
    "### 1. pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "215728e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([[1,2,3], [2,3,4], [4,5,6]]), torch.tensor([[3,4, 5]])]\n",
    "a_pad = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)\n",
    "\n",
    "b = [torch.tensor([1,2,3]), torch.tensor([3,4])]\n",
    "b_pad = torch.nn.utils.rnn.pad_sequence(b, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ae05050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 2, 3],\n",
       "         [2, 3, 4],\n",
       "         [4, 5, 6]]),\n",
       " tensor([[3, 4, 5]])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5326aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [2, 3, 4],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[3, 4, 5],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be983fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eba29fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28361c07",
   "metadata": {},
   "source": [
    "### pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7e37f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1, 2, 3],\n",
       "        [3, 4, 5],\n",
       "        [2, 3, 4],\n",
       "        [4, 5, 6]]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pack = torch.nn.utils.rnn.pack_padded_sequence(a_pad, batch_first=True, lengths=[3,1])\n",
    "a_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2248a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 3, 2, 4, 3]), batch_sizes=tensor([2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pack = torch.nn.utils.rnn.pack_padded_sequence(b_pad, batch_first=True, lengths=[3,2])\n",
    "b_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c0e28",
   "metadata": {},
   "source": [
    "### pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f2db759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [2, 3, 4],\n",
       "          [4, 5, 6]],\n",
       " \n",
       "         [[3, 4, 5],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]]),\n",
       " (tensor([[[1, 2, 3],\n",
       "           [2, 3, 4],\n",
       "           [4, 5, 6]],\n",
       "  \n",
       "          [[3, 4, 5],\n",
       "           [0, 0, 0],\n",
       "           [0, 0, 0]]]),\n",
       "  tensor([3, 1])))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_reverse_pack = torch.nn.utils.rnn.pad_packed_sequence(a_pack, batch_first=True)\n",
    "a_pad, a_reverse_pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89b69d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [3, 4, 0]]),\n",
       " (tensor([[1, 2, 3],\n",
       "          [3, 4, 0]]),\n",
       "  tensor([3, 2])))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reverse_pack = torch.nn.utils.rnn.pad_packed_sequence(b_pack, batch_first=True)\n",
    "b_pad, b_reverse_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cabbc",
   "metadata": {},
   "source": [
    "## Note\n",
    "### 1. pad_sequence does not sort sequence by seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da6a34df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "c = [torch.ones(5, 10), torch.ones(7, 10), torch.ones(3, 10)]\n",
    "c_pad = pad_sequence(c, batch_first=True)\n",
    "c_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb2856",
   "metadata": {},
   "source": [
    "### 2. but pack_padded_sequence wants a sorted pad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7b38d41",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_299729/436231044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc_pack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability."
     ]
    }
   ],
   "source": [
    "c_pack = torch.nn.utils.rnn.pack_padded_sequence(c_pad, batch_first=True, lengths=[5,7,3])\n",
    "c_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516eaca",
   "metadata": {},
   "source": [
    "### 3. set enforce_sorted=False or padding manuly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db919780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), batch_sizes=tensor([3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([1, 0, 2]), unsorted_indices=tensor([1, 0, 2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_pack = torch.nn.utils.rnn.pack_padded_sequence(c_pad, batch_first=True, lengths=[5,7,3], enforce_sorted=False)\n",
    "c_pack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429284b",
   "metadata": {},
   "source": [
    "### 4. sorted_indices & unsorted_indices are not none only if enforce_sorted=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8728333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a1546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65771a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad48b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
