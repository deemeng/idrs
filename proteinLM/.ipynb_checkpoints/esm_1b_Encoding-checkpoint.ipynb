{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f92014bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd242ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae3fd0",
   "metadata": {},
   "source": [
    "# 1. Main Models\n",
    "\n",
    "ESM-1b (UR50): *esm1b_t33_650M_UR50S()*\n",
    "\n",
    "ESM-MSA-1b (UR50 + MSA): *esm_msa1b_t12_100M_UR50S()*\n",
    "\n",
    "ESM-1v (UR90): *esm1v_t33_650M_UR90S_\\[1-5\\]()*\n",
    "\n",
    "ESM-IF1 (CATH + UR50): *esm_if1_gvp4_t16_142M_UR50()*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f138f91",
   "metadata": {},
   "source": [
    "> Note that here we use ESM-1b model. May try others later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d85b96",
   "metadata": {},
   "source": [
    "## 1.1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd21ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt\" to /home/qinqin/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm1b_t33_650M_UR50S-contact-regression.pt\" to /home/qinqin/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S-contact-regression.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinBertModel(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (16): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (17): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (18): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (19): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (20): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (21): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (22): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (23): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (24): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (25): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (26): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (27): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (28): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (29): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (30): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (31): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (32): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
       "  (emb_layer_norm_before): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ESM-1b model\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "model.max_positions=20000\n",
    "model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81587103",
   "metadata": {},
   "source": [
    "## 1.2. data & generating representaion\n",
    "> batch_converter(raw_batch: Sequence[Tuple[str, str]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b2755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"protein1\", \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"),\n",
    "    (\"protein2\", \"KALTARQQEVFDLIRDHISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "    (\"protein2 with mask\",\"KALTARQQEVFDLIRD<mask>ISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "    (\"protein3\",  \"K A <mask> I S Q\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "714debe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protein1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ced9e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f108842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 67])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b7930",
   "metadata": {},
   "source": [
    "## 1.3. usage\n",
    "\n",
    "**Token representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e6319f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bf98740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 67, 1280])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_representations.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e1c420",
   "metadata": {},
   "source": [
    "**Sequence Representation**\n",
    "\n",
    "Take the mean(AA) of token representation. Not using yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f8a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d927b6d",
   "metadata": {},
   "source": [
    "# 2. Load protein dataset \n",
    "> csv file, cdhit clusters (all=curated+derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5730a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_allInfo = '/home/qinqin/dimeng/idrs/pycode/data/all_cdhit_info.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7d9c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allInfo = pd.read_csv(PATH_allInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "763e6892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_index</th>\n",
       "      <th>cluster</th>\n",
       "      <th>p_identity</th>\n",
       "      <th>cluster_orign</th>\n",
       "      <th>cluster_i</th>\n",
       "      <th>source_x</th>\n",
       "      <th>p_len</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>annotation_method</th>\n",
       "      <th>annotation</th>\n",
       "      <th>description</th>\n",
       "      <th>protein_length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>source_y</th>\n",
       "      <th>taxid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q8WZ42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Q8WZ42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>curated</td>\n",
       "      <td>34350</td>\n",
       "      <td>Q8WZ42</td>\n",
       "      <td>curated-disorder-merge</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>Titin OS=Homo sapiens (Human) OX=9606 GN=TTN</td>\n",
       "      <td>34350</td>\n",
       "      <td>MTTQAPTFTQPLQSVVVLEGSTATFEAHISGFPVPEVSWFRDGQVI...</td>\n",
       "      <td>curated_merge_disorder</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>M9PB30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>M9PB30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>22949</td>\n",
       "      <td>M9PB30</td>\n",
       "      <td>derived-mobile-th_90</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>OS=Drosophila melanogaster (Fruit fly) OX=7227...</td>\n",
       "      <td>22949</td>\n",
       "      <td>MKIFLPLVTWIVLLLSSAVHSQYSQQPQPFKTNLRANSRFRGEVFY...</td>\n",
       "      <td>derived_mobi_mobile</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>G4SLH0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>G4SLH0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>curated</td>\n",
       "      <td>18562</td>\n",
       "      <td>G4SLH0</td>\n",
       "      <td>curated-disorder-merge</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>Titin homolog OS=Caenorhabditis elegans OX=623...</td>\n",
       "      <td>18562</td>\n",
       "      <td>MEGNEKKGGGLPPTQQRHLNIDTTVGGSISQPVSPSMSYSTDRETV...</td>\n",
       "      <td>curated_merge_disorder</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Q03132</td>\n",
       "      <td>40.98</td>\n",
       "      <td>Q6MZA4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>curated</td>\n",
       "      <td>3567</td>\n",
       "      <td>Q03132</td>\n",
       "      <td>curated-disorder-merge</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>6-deoxyerythronolide-B synthase EryA2, modules...</td>\n",
       "      <td>3567</td>\n",
       "      <td>MTDSEKVAEYLRRATLDLRAARQRIRELESDPIAIVSMACRLPGGV...</td>\n",
       "      <td>curated_merge_disorder</td>\n",
       "      <td>1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Q8NWQ6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Q8NWQ6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>9904</td>\n",
       "      <td>Q8NWQ6</td>\n",
       "      <td>derived-missing_residues-th_90</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>Extracellular matrix-binding protein ebh OS=St...</td>\n",
       "      <td>9904</td>\n",
       "      <td>MNYRDKIQKFSIRKYTVGTFSTVIATLVFLGFNTSQAHAAETNQPA...</td>\n",
       "      <td>derived_mobi_missing</td>\n",
       "      <td>196620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_index cluster  p_identity cluster_orign  cluster_i source_x  p_len  \\\n",
       "0        0  Q8WZ42        1.00        Q8WZ42        0.0  curated  34350   \n",
       "1        0  M9PB30        1.00        M9PB30        1.0   mobile  22949   \n",
       "2        0  G4SLH0        1.00        G4SLH0        2.0  curated  18562   \n",
       "3       11  Q03132       40.98        Q6MZA4        3.0  curated   3567   \n",
       "4        0  Q8NWQ6        1.00        Q8NWQ6        4.0  missing   9904   \n",
       "\n",
       "  protein_name               annotation_method  \\\n",
       "0       Q8WZ42          curated-disorder-merge   \n",
       "1       M9PB30            derived-mobile-th_90   \n",
       "2       G4SLH0          curated-disorder-merge   \n",
       "3       Q03132          curated-disorder-merge   \n",
       "4       Q8NWQ6  derived-missing_residues-th_90   \n",
       "\n",
       "                                          annotation  \\\n",
       "0  0000000000000000000000000000000000000000000000...   \n",
       "1  0000000000000000000000000000000000000000000000...   \n",
       "2  0000000000000000000000000000000000000000000000...   \n",
       "3  0000000000000000000000000000000000000000000000...   \n",
       "4  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                         description  protein_length  \\\n",
       "0       Titin OS=Homo sapiens (Human) OX=9606 GN=TTN           34350   \n",
       "1  OS=Drosophila melanogaster (Fruit fly) OX=7227...           22949   \n",
       "2  Titin homolog OS=Caenorhabditis elegans OX=623...           18562   \n",
       "3  6-deoxyerythronolide-B synthase EryA2, modules...            3567   \n",
       "4  Extracellular matrix-binding protein ebh OS=St...            9904   \n",
       "\n",
       "                                            sequence                source_y  \\\n",
       "0  MTTQAPTFTQPLQSVVVLEGSTATFEAHISGFPVPEVSWFRDGQVI...  curated_merge_disorder   \n",
       "1  MKIFLPLVTWIVLLLSSAVHSQYSQQPQPFKTNLRANSRFRGEVFY...     derived_mobi_mobile   \n",
       "2  MEGNEKKGGGLPPTQQRHLNIDTTVGGSISQPVSPSMSYSTDRETV...  curated_merge_disorder   \n",
       "3  MTDSEKVAEYLRRATLDLRAARQRIRELESDPIAIVSMACRLPGGV...  curated_merge_disorder   \n",
       "4  MNYRDKIQKFSIRKYTVGTFSTVIATLVFLGFNTSQAHAAETNQPA...    derived_mobi_missing   \n",
       "\n",
       "    taxid  \n",
       "0    9606  \n",
       "1    7227  \n",
       "2    6239  \n",
       "3    1836  \n",
       "4  196620  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allInfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6967fd",
   "metadata": {},
   "source": [
    "# 3. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5ef4b",
   "metadata": {},
   "source": [
    "## 3.1. processing data\n",
    "\n",
    "### Bug\n",
    "> ValueError: Sequence length 34352 above maximum  sequence length of 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b815ea4",
   "metadata": {},
   "source": [
    "### keep seq which len<=1024\n",
    "> 19076 out of 20625, ~92.5% sequence left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1e4f543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_allInfo['protein_length'].plot.hist(figsize=(12, 8), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e6a929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pd.DataFrame.plot.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7a48f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248969696969697"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info1024 = df_allInfo[df_allInfo['protein_length']<=1024]\n",
    "df_info1024.shape[0]/df_allInfo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20043d",
   "metadata": {},
   "source": [
    "## 3.2. Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "66851fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_info1024, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bab571",
   "metadata": {},
   "source": [
    "## 3.3. Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bb3c4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aim:\n",
    "    Encoding sequence first, then save it to file fpath.\n",
    "params:\n",
    "    df_info: Dataframe, contains protein_name, protein_length, annotation and sequence at least!\n",
    "    fpath: str, path to save encoding dataset. same form as one-hot encoding.\n",
    "'''\n",
    "def saveEncoding(df_info, fpath):\n",
    "    with open(fpath, 'w') as f:\n",
    "        f.write(str(df_info.shape[0]))\n",
    "        f.write('\\n')\n",
    "        f.write('1280 2')\n",
    "        f.write('\\n')\n",
    "        for index, row in df_info.iterrows():\n",
    "            \n",
    "            ###\n",
    "            # 1. Encoding\n",
    "            ###\n",
    "            data = [(row['protein_name'], row['sequence'])]\n",
    "            batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "            # Extract per-residue representations (on CPU)\n",
    "            with torch.no_grad():\n",
    "                results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "            token_representations = results[\"representations\"][33]\n",
    "            token_representations = token_representations.reshape(-1).tolist()\n",
    "            \n",
    "            ###\n",
    "            # 2. saving\n",
    "            ###\n",
    "            f.write(row['protein_name'])\n",
    "            f.write('\\n')\n",
    "            # f.write(row['annotation_method'])\n",
    "            # f.write('\\n')\n",
    "            f.write(str(row['protein_length']))\n",
    "            f.write('\\n')\n",
    "            # f.write(''.join(map(str, row['encoded_seq']))[2:-2])\n",
    "            f.write(' '.join(str(x) for x in token_representations))\n",
    "            # f.write(''.join(map(str, row['encoded_seq'][0])))\n",
    "            f.write('\\n')\n",
    "            # f.write(seq_flatten(row['annotation']))\n",
    "            f.write(\" \".join(row['annotation']))\n",
    "            f.write('\\n')\n",
    "            f.write('\\n')\n",
    "        f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c641f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_train = '/home/qinqin/dimeng/idrs/pycode/data/esm_1b_train.txt'\n",
    "fpath_test = '/home/qinqin/dimeng/idrs/pycode/data/esm_1b_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a99eb6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveEncoding(df_train, fpath_train)\n",
    "saveEncoding(df_test, fpath_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
