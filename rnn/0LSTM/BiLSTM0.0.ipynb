{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c49fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "\n",
    "# import hyperparameters\n",
    "from brnn_hyperparams import *\n",
    "# from model import BRNN\n",
    "from utils import load_dataset, get_num_class\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# processing bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'{model_name}board_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28181e2",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbea74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.setLevel(logging.INFO)\n",
    "# logging.basicConfig(level=logging.NOTSET)\n",
    "logging.basicConfig(filename=log_name+'_test', \n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %P',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db91d1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.warning('Device: ' + device.type)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cf1f5",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3be1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fpath):\n",
    "    '''\n",
    "    params:\n",
    "        fpath - path to fasta file, training or test\n",
    "                ***The format of the sets:\n",
    "\n",
    "                The first two lines are a global header:\n",
    "                total_number_of_records\n",
    "                input_size number_of_classes\n",
    "\n",
    "                total_number_of_records is simply the number of proteins in the set,\n",
    "                input_size is how many numbers are used to represent one amino acid (21\n",
    "                or 22, probably, in your case) and number_of_classes is the number of\n",
    "                classes...\n",
    "\n",
    "                After that you have the proteins, 5 lines each:\n",
    "\n",
    "                line 1: name of the protein\n",
    "                line 2: number of amino acids in the protein\n",
    "                line 3: input\n",
    "                line 4: targets\n",
    "                line 5: empty\n",
    "\n",
    "                You can use any name you want so long as it's unique, a single word, and\n",
    "                not outrageously long.\n",
    "\n",
    "                The input should be a single long list of the numbers representing the\n",
    "                amino acids in the protein. If you use, say, 21 numbers per amino acid,\n",
    "                and the protein is 100 amino acids long, the input line will contain\n",
    "                2100 numbers, with the first 21 being the representation of the first\n",
    "                amino acid in the protein, the following 21 the representation of the\n",
    "                second, etc.\n",
    "                For the moment (before we use alignments) the representation of an amino\n",
    "                acid will be a one-hot encoding, e.g.:\n",
    "\n",
    "                A     -> 1 0 0 0 ..... 0 0\n",
    "                C     -> 0 1 0 0 ..... 0 0\n",
    "                ...\n",
    "                Y     -> 0 0 0 0 ..... 1 0\n",
    "                other -> 0 0 0 0 ..... 0 1\n",
    "\n",
    "                where \"other\" is unknown or weird amino acid (X, B, J, O, U, Z)\n",
    "\n",
    "                The line containing the targets is a list of integers representing the\n",
    "                classes of the amino acids. There are as many integers as there are\n",
    "                amino acids in the protein. You can choose whatever integers you want,\n",
    "                but it's probably simplest to have something like class1=0, class2=1,\n",
    "                class3=2, etc..\n",
    "\n",
    "                (notice that in the sample sets in the directory you have a more\n",
    "                complicated representation of the inputs, where there are a lot of\n",
    "                floating point numbers rather than just 0 and 1, and that's because\n",
    "                those inputs are frequency profiles from MSA - so you can see how the\n",
    "                code works for both kinds of inputs)\n",
    "                \n",
    "    returns:\n",
    "        p_data - list[data_tensor, target_tensor]\n",
    "        p_lens - list, protein length\n",
    "    \n",
    "    Note: \n",
    "        - the reason not using tensor to save protein Sequences and Targets is we have varying length sequences! \n",
    "        - solve this problem we could consider pading. But our dataset lens range from about 20 to 10,000. \n",
    "            Thus, padding maybe not a good idea here.\n",
    "    '''\n",
    "    num_protein = 0\n",
    "    num_i = 0\n",
    "    num_o = 0\n",
    "\n",
    "    # p_names = []\n",
    "    p_lens = []\n",
    "    # p_seqs = []\n",
    "    # p_anns = []\n",
    "    p_data = []\n",
    "    with open(fpath) as fp:\n",
    "        num_protein = int(fp.readline())\n",
    "        num_io = fp.readline().split(' ')\n",
    "        num_i = int(num_io[0])\n",
    "        num_o = int(num_io[0])\n",
    "\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            # p_name = line[:-1]\n",
    "            p_len = int(fp.readline())\n",
    "            p_sequence = torch.tensor([int(x) for x in fp.readline().split(' ')], \n",
    "                                      dtype=torch.float32).reshape(-1, 21)\n",
    "            p_annotation = torch.tensor([[int(x)] for x in fp.readline().split(' ')], dtype=torch.float32)\n",
    "            # skip empty\n",
    "            next(fp)\n",
    "            # p_names.append(p_name)\n",
    "            p_lens.append(p_len)\n",
    "            # p_seqs.append(p_sequence)\n",
    "            # p_anns.append(p_annotation)\n",
    "            p_data.append([p_sequence, p_annotation])\n",
    "            line = fp.readline()   \n",
    "    return p_data, p_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "450940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fpath, transform=None):\n",
    "        self.p_data, self.p_lens = load_dataset(fpath)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.p_lens)\n",
    "    \n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        # self.p_data[i][0], sequence;  self.p_data[i][1], label\n",
    "        return self.p_data[i][0], self.p_data[i][1]\n",
    "    def __numAAs__(self) -> int:\n",
    "        return sum(self.p_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39c98dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_class(input_data):\n",
    "    '''\n",
    "    params:\n",
    "        input_data - p_data format return from load_dataset function.\n",
    "        \n",
    "    returns:\n",
    "        c0 - the number of amino acids of class 0, which means ordered.\n",
    "        c1 - the number of amino acids of class 1, which means disordered.\n",
    "    '''\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    for batch_idx, (data, target) in enumerate(input_data):\n",
    "        c0 = c0 + len(target) - target.sum()\n",
    "        c1 = c1 + target.sum()\n",
    "    return c0, c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b463f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocPlot(train_label, train_probs, val_label, val_probs):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    fpr, tpr, thresholds = roc_curve(train_label, train_probs)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=model_name+\" ROC curve (area = %0.2f)\" % roc_auc,\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Training\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(val_label, val_probs)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=model_name+\" ROC curve (area = %0.2f)\" % roc_auc,\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Validation\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e6e5e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ed1c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!\n",
    "# file need extra one empty line\n",
    "# !!!!\n",
    "logging.warning('Loading training file ...')\n",
    "train_ds = ProteinDataset(train_fpath)\n",
    "logging.warning('Loading test file ...')\n",
    "test_ds = ProteinDataset(test_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0756d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.p_data[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55acabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size = 1, num_workers = 72, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "660feabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning('Training set: ' + str(len(train_ds.p_lens)))\n",
    "logging.warning('Test set:     ' + str(len(test_ds.p_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba5834",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c463250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                         bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        print('h0: ', h0.size())\n",
    "        print('c0: ', c0.size())\n",
    "        # Forward Prop\n",
    "        # out, (hn, cn) = self.lstm(x,  (h0, c0))\n",
    "        # out, _ = self.lstm(x,  (h0, c0))\n",
    "        out, (hn, cn) = self.lstm(x,  (h0, c0))\n",
    "        print('out: ', out.size())\n",
    "        print('hn: ', hn.size())\n",
    "        print('cn: ', cn.size())\n",
    "        # all training example, last hidden state, all \n",
    "        # it is not last hidden state, it is the last batch\n",
    "        print('out.squeeze() ', out.squeeze().size())\n",
    "        out = self.fc(out.squeeze())\n",
    "        print('out final: ', out.size())\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def train_batch(self, train_loader, optimizer, criterion):\n",
    "        # set training state to model\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        \n",
    "        with tqdm(total=len(train_loader), position=0) as progress_bar:\n",
    "            for batch_idx, (data, label) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self(data)\n",
    "                loss = criterion(output, label.squeeze(0))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "    def val_batch(self, val_data, criterion): \n",
    "        # set evaluation state to the model\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        losses = []\n",
    "        \n",
    "        class_probs = []\n",
    "        class_label = []\n",
    "        \n",
    "        # no gradient needed\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_data):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                # forward\n",
    "                scores = self(data)\n",
    "                loss = criterion(scores, target.squeeze(0))\n",
    "                # ERROR\n",
    "                losses.append(loss.cpu()) # loss for each batch\n",
    "                # save for ploting curve\n",
    "                class_probs.append(scores.squeeze(-1).cpu())\n",
    "                class_label.append(target.cpu())\n",
    "                \n",
    "        # overall loss\n",
    "        loss = np.mean(losses)\n",
    "        return loss, class_probs, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f68eb",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "675c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = BRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "# propogation of two classes\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43d059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f109dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                            | 3/16500 [00:04<5:04:40,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 257, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([257, 48])\n",
      "out final:  torch.Size([257, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 160, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([160, 48])\n",
      "out final:  torch.Size([160, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 459, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([459, 48])\n",
      "out final:  torch.Size([459, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                            | 5/16500 [00:04<2:43:50,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 307, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([307, 48])\n",
      "out final:  torch.Size([307, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 291, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([291, 48])\n",
      "out final:  torch.Size([291, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 704, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([704, 48])\n",
      "out final:  torch.Size([704, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                            | 7/16500 [00:04<1:42:48,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 270, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([270, 48])\n",
      "out final:  torch.Size([270, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 1032, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([1032, 48])\n",
      "out final:  torch.Size([1032, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 274, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([274, 48])\n",
      "out final:  torch.Size([274, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 12/16500 [00:04<47:13,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 229, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([229, 48])\n",
      "out final:  torch.Size([229, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 334, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([334, 48])\n",
      "out final:  torch.Size([334, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 326, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([326, 48])\n",
      "out final:  torch.Size([326, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 128, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([128, 48])\n",
      "out final:  torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                             | 15/16500 [00:05<34:20,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 321, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([321, 48])\n",
      "out final:  torch.Size([321, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 347, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([347, 48])\n",
      "out final:  torch.Size([347, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 80, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([80, 48])\n",
      "out final:  torch.Size([80, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 96, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([96, 48])\n",
      "out final:  torch.Size([96, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 220, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([220, 48])\n",
      "out final:  torch.Size([220, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 20/16500 [00:05<23:16, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 293, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([293, 48])\n",
      "out final:  torch.Size([293, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 285, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([285, 48])\n",
      "out final:  torch.Size([285, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 152, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([152, 48])\n",
      "out final:  torch.Size([152, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 247, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([247, 48])\n",
      "out final:  torch.Size([247, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 24/16500 [00:05<19:35, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 105, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([105, 48])\n",
      "out final:  torch.Size([105, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 541, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([541, 48])\n",
      "out final:  torch.Size([541, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 350, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([350, 48])\n",
      "out final:  torch.Size([350, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 326, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 28/16500 [00:05<18:11, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.squeeze()  torch.Size([326, 48])\n",
      "out final:  torch.Size([326, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 493, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([493, 48])\n",
      "out final:  torch.Size([493, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 347, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([347, 48])\n",
      "out final:  torch.Size([347, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 33/16500 [00:06<15:08, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:  torch.Size([1, 238, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([238, 48])\n",
      "out final:  torch.Size([238, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 162, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([162, 48])\n",
      "out final:  torch.Size([162, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 46, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([46, 48])\n",
      "out final:  torch.Size([46, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 360, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([360, 48])\n",
      "out final:  torch.Size([360, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 124, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([124, 48])\n",
      "out final:  torch.Size([124, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                            | 36/16500 [00:06<15:07, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:  torch.Size([1, 102, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([102, 48])\n",
      "out final:  torch.Size([102, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 317, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([317, 48])\n",
      "out final:  torch.Size([317, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 411, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([411, 48])\n",
      "out final:  torch.Size([411, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 390, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([390, 48])\n",
      "out final:  torch.Size([390, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                            | 40/16500 [00:06<15:43, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 243, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([243, 48])\n",
      "out final:  torch.Size([243, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 252, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([252, 48])\n",
      "out final:  torch.Size([252, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 545, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([545, 48])\n",
      "out final:  torch.Size([545, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 332, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([332, 48])\n",
      "out final:  torch.Size([332, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                            | 43/16500 [00:06<16:01, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 75, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([75, 48])\n",
      "out final:  torch.Size([75, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 783, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([783, 48])\n",
      "out final:  torch.Size([783, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 155, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([155, 48])\n",
      "out final:  torch.Size([155, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                            | 45/16500 [00:06<17:56, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 590, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([590, 48])\n",
      "out final:  torch.Size([590, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 84, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([84, 48])\n",
      "out final:  torch.Size([84, 1])\n",
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 2488, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([2488, 48])\n",
      "out final:  torch.Size([2488, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                            | 46/16500 [00:07<44:29,  6.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_244179/2580429055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# acc & loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_244179/4282085866.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate}\")\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.warning('*********************************')\n",
    "    logging.warning('epoch: ' + str(epoch))\n",
    "    logging.warning('*********************************')\n",
    "    ################\n",
    "    # 3.1. Training\n",
    "    ################\n",
    "    logging.warning('1. TRAINING:')\n",
    "    # plot pr and roc curve or not\n",
    "    plot_pr_roc = (epoch % plot_nEpoch == 0)\n",
    "\n",
    "    # training\n",
    "    model.train_batch(train_dl, optimizer, criterion)\n",
    "    \n",
    "    # acc & loss\n",
    "    train_loss, t_class_probs, t_class_label = model.val_batch(train_dl, criterion)\n",
    "    val_loss, v_class_probs, v_class_label = model.val_batch(test_dl, criterion)\n",
    "    \n",
    "    # val_accs.append(val_acc)\n",
    "    \n",
    "    print('Training: Loss:')\n",
    "    print(train_loss)\n",
    "    \n",
    "    print('VAL: Loss:')\n",
    "    print(val_loss)\n",
    "    \n",
    "    logging.warning('Training:')\n",
    "    logging.warning(f'Loss: {train_loss}')\n",
    "\n",
    "    logging.warning('Validation:')\n",
    "    logging.warning(f'Loss: {val_loss}')\n",
    "    \n",
    "    ##\n",
    "    # for tensorboard plots\n",
    "    ##\n",
    "    writer.add_scalar(\"TRAIN: loss\", train_loss, epoch)\n",
    "    #writer.add_scalar(\"TRAIN: acc\", train_acc, epoch)\n",
    "    \n",
    "    writer.add_scalar(\"VAL: loss\", val_loss, epoch)\n",
    "    #writer.add_scalar(\"VAL: acc\", val_acc, epoch)\n",
    "    \n",
    "    ##\n",
    "    # PR-curve & ROC-curve\n",
    "    ##\n",
    "    if plot_pr_roc:\n",
    "        train_probs = torch.cat([batch for batch in t_class_probs])\n",
    "        train_label = torch.cat(t_class_label)\n",
    "\n",
    "        writer.add_pr_curve(f'TRAIN: pr_curve e{epoch}', train_label.reshape(-1), train_probs, 0)\n",
    "\n",
    "        val_probs = torch.cat([batch for batch in v_class_probs])\n",
    "        val_label = torch.cat(v_class_label)\n",
    "\n",
    "        writer.add_pr_curve(f'VAL: pr_curve e{epoch}', val_label.reshape(-1), val_probs, 0)\n",
    "\n",
    "        roc_fig = rocPlot(train_label.reshape(-1), train_probs, val_label.reshape(-1), val_probs)\n",
    "        writer.add_figure(f'Train vs VAL: roc_curve e{epoch}', roc_fig)\n",
    "    ##\n",
    "    # Save model every m epochs\n",
    "    ##\n",
    "    if epoch % checkpoint_m == 0:\n",
    "        cPATH = f\"checkpoint/{model_name}_{epoch}.pth\"\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    }, cPATH)\n",
    "        \n",
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate} \\n \")\n",
    "                # best_val_epoch: {int(np.argmax(val_accs)+1)}\") # the best val epoch\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "017da9c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([8, 1, 24])\n",
      "c0:  torch.Size([8, 1, 24])\n",
      "out:  torch.Size([1, 2000, 48])\n",
      "hn:  torch.Size([8, 1, 24])\n",
      "cn:  torch.Size([8, 1, 24])\n",
      "out.squeeze()  torch.Size([2000, 48])\n",
      "out final:  torch.Size([2000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BRNN                                     [2000, 1]                 --\n",
       "├─LSTM: 1-1                              [1, 2000, 48]             51,648\n",
       "├─Linear: 1-2                            [2000, 1]                 49\n",
       "├─Sigmoid: 1-3                           [2000, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 51,697\n",
       "Trainable params: 51,697\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 103.39\n",
       "==========================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 0.78\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 1.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "seq_len = 2000\n",
    "summary(model, input_size=(1, seq_len, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cde796d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRNN(\n",
      "  (lstm): LSTM(21, 24, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=48, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dd3b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 2000, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([2000, 48])\n",
      "out final:  torch.Size([2000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BRNN                                     [2000, 1]                 --\n",
       "├─LSTM: 1-1                              [1, 2000, 48]             23,232\n",
       "├─Linear: 1-2                            [2000, 1]                 49\n",
       "├─Sigmoid: 1-3                           [2000, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 23,281\n",
       "Trainable params: 23,281\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 46.56\n",
       "==========================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 0.78\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 1.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "seq_len = 2000\n",
    "summary(model, input_size=(1, seq_len, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccbb2cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_244179/1332726764.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.reshape(1, data.shape[0], data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa027334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215728e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
