{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c49fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "# import hyperparameters\n",
    "from brnn_hyperparams import *\n",
    "# from model import BRNN\n",
    "# from utils import load_dataset, get_num_class\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# processing bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'{model_name}board_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28181e2",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbea74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.setLevel(logging.INFO)\n",
    "# logging.basicConfig(level=logging.NOTSET)\n",
    "logging.basicConfig(filename=log_name+'_test', \n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %P',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db91d1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.warning('Device: ' + device.type)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc9627",
   "metadata": {},
   "source": [
    "### Test hyperpramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9ccd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_fpath = root_path + '/data/train'\n",
    "test_fpath = root_path + '/data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cf1f5",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3be1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fpath):\n",
    "    '''\n",
    "    params:\n",
    "        fpath - path to fasta file, training or test\n",
    "                ***The format of the sets:\n",
    "\n",
    "                The first two lines are a global header:\n",
    "                total_number_of_records\n",
    "                input_size number_of_classes\n",
    "\n",
    "                total_number_of_records is simply the number of proteins in the set,\n",
    "                input_size is how many numbers are used to represent one amino acid (21\n",
    "                or 22, probably, in your case) and number_of_classes is the number of\n",
    "                classes...\n",
    "\n",
    "                After that you have the proteins, 5 lines each:\n",
    "\n",
    "                line 1: name of the protein\n",
    "                line 2: number of amino acids in the protein\n",
    "                line 3: input\n",
    "                line 4: targets\n",
    "                line 5: empty\n",
    "\n",
    "                You can use any name you want so long as it's unique, a single word, and\n",
    "                not outrageously long.\n",
    "\n",
    "                The input should be a single long list of the numbers representing the\n",
    "                amino acids in the protein. If you use, say, 21 numbers per amino acid,\n",
    "                and the protein is 100 amino acids long, the input line will contain\n",
    "                2100 numbers, with the first 21 being the representation of the first\n",
    "                amino acid in the protein, the following 21 the representation of the\n",
    "                second, etc.\n",
    "                For the moment (before we use alignments) the representation of an amino\n",
    "                acid will be a one-hot encoding, e.g.:\n",
    "\n",
    "                A     -> 1 0 0 0 ..... 0 0\n",
    "                C     -> 0 1 0 0 ..... 0 0\n",
    "                ...\n",
    "                Y     -> 0 0 0 0 ..... 1 0\n",
    "                other -> 0 0 0 0 ..... 0 1\n",
    "\n",
    "                where \"other\" is unknown or weird amino acid (X, B, J, O, U, Z)\n",
    "\n",
    "                The line containing the targets is a list of integers representing the\n",
    "                classes of the amino acids. There are as many integers as there are\n",
    "                amino acids in the protein. You can choose whatever integers you want,\n",
    "                but it's probably simplest to have something like class1=0, class2=1,\n",
    "                class3=2, etc..\n",
    "\n",
    "                (notice that in the sample sets in the directory you have a more\n",
    "                complicated representation of the inputs, where there are a lot of\n",
    "                floating point numbers rather than just 0 and 1, and that's because\n",
    "                those inputs are frequency profiles from MSA - so you can see how the\n",
    "                code works for both kinds of inputs)\n",
    "                \n",
    "    returns:\n",
    "        p_data - list[data_tensor, target_tensor]\n",
    "        p_lens - list, protein length\n",
    "    \n",
    "    Note: \n",
    "        - the reason not using tensor to save protein Sequences and Targets is we have varying length sequences! \n",
    "        - solve this problem we could consider pading. But our dataset lens range from about 20 to 10,000. \n",
    "            Thus, padding maybe not a good idea here.\n",
    "        - to solve variance sequences problem, we can use pad_sequence, pack_padded_sequence & \n",
    "    '''\n",
    "    num_protein = 0\n",
    "    num_i = 0\n",
    "    num_o = 0\n",
    "\n",
    "    # p_names = []\n",
    "    p_lens = []\n",
    "    # p_seqs = []\n",
    "    # p_anns = []\n",
    "    p_data = []\n",
    "    with open(fpath) as fp:\n",
    "        num_protein = int(fp.readline())\n",
    "        num_io = fp.readline().split(' ')\n",
    "        num_i = int(num_io[0])\n",
    "        num_o = int(num_io[0])\n",
    "\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            # p_name = line[:-1]\n",
    "            p_len = int(fp.readline())\n",
    "            p_sequence = torch.tensor([int(x) for x in fp.readline().split(' ')], \n",
    "                                      dtype=torch.float32).reshape(-1, 21)\n",
    "            p_annotation = torch.tensor([[int(x)] for x in fp.readline().split(' ')], dtype=torch.float32)\n",
    "            # skip empty\n",
    "            next(fp)\n",
    "            # p_names.append(p_name)\n",
    "            p_lens.append(p_len)\n",
    "            # p_seqs.append(p_sequence)\n",
    "            # p_anns.append(p_annotation)\n",
    "            p_data.append([p_sequence, p_annotation])\n",
    "            line = fp.readline()   \n",
    "    return p_data, p_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fpath, transform=None):\n",
    "        self.p_data, self.p_lens = load_dataset(fpath)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.p_lens)\n",
    "    \n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        # self.p_data[i][0], sequence;  self.p_data[i][1], label\n",
    "        return self.p_data[i][0], self.p_data[i][1]\n",
    "    def numAAs(self) -> int:\n",
    "        return sum(self.p_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43277d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_packed_collate(batch):\n",
    "    \"\"\"Puts data, and lengths into a packed_padded_sequence then returns\n",
    "       the packed_padded_sequence and the labels. Set use_lengths to True\n",
    "       to use this collate function.\n",
    "       Args:\n",
    "         batch: (list of tuples) [(sequence, target)].\n",
    "             sequence is a FloatTensor\n",
    "             target has the same variable length with sequence\n",
    "       Output:\n",
    "         packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "         labels: (Tensor), labels from the file names of the wav.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(batch) == 1:\n",
    "        seqs, labels = [batch[0][0]], [batch[0][1]]\n",
    "        lengths = [seqs[0].size(0)]\n",
    "        \n",
    "    if len(batch) > 1:\n",
    "        # get data and sorted by the length of sequence\n",
    "        seqs, labels, lengths = zip(*[(a, b, a.size(0)) for (a,b) in sorted(batch, key=lambda x: x[0].size(0), reverse=True)])\n",
    "    seqs = pad_sequence(seqs, batch_first=True)\n",
    "    labels = pad_sequence(labels, batch_first=True)\n",
    "    packed_seqs = pack_padded_sequence(seqs, lengths, batch_first=True)\n",
    "    packed_labels = pack_padded_sequence(labels, lengths, batch_first=True)\n",
    "    \n",
    "    return packed_seqs, packed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b463f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocPlot(train_label, train_probs, val_label, val_probs):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    t_fpr, t_tpr, t_thresholds = roc_curve(train_label, train_probs)\n",
    "    t_roc_auc = auc(t_fpr, t_tpr)\n",
    "    v_fpr, v_tpr, v_thresholds = roc_curve(val_label, val_probs)\n",
    "    v_roc_auc = auc(v_fpr, v_tpr)\n",
    "    \n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        t_fpr,\n",
    "        t_tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"Training (area = %0.2f)\" % t_roc_auc,\n",
    "    )\n",
    "    \n",
    "    plt.plot(\n",
    "        v_fpr,\n",
    "        v_tpr,\n",
    "        color=\"darkgreen\",\n",
    "        lw=lw,\n",
    "        label=\"Val (area = %0.2f)\" % v_roc_auc,\n",
    "    )\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(model_name+\": Train & Val ROC curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e6e5e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed1c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!\n",
    "# file need extra one empty line\n",
    "# !!!!\n",
    "logging.warning('Loading training file ...')\n",
    "train_ds = ProteinDataset(train_fpath)\n",
    "logging.warning('Loading test file ...')\n",
    "test_ds = ProteinDataset(test_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0756d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.p_data[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55acabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "# using pad_packed_collate to deal with padding\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, num_workers = 72, shuffle=True, collate_fn=pad_packed_collate)\n",
    "test_dl = DataLoader(test_ds, batch_size = batch_size, num_workers = 72, shuffle=False, collate_fn=pad_packed_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660feabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning('Training set: ' + str(len(train_ds.p_lens)))\n",
    "logging.warning('Test set:     ' + str(len(test_ds.p_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cf19e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, label) in enumerate(train_dl):\n",
    "#     print(data.batch_sizes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba5834",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c463250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropP = 0.5):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                         bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.drop = nn.Dropout(p = dropP)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.batch_sizes[0], self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.batch_sizes[0], self.hidden_size).to(device)\n",
    "        # Forward Prop\n",
    "        # out, (hn, cn) = self.lstm(x,  (h0, c0))\n",
    "        # out, _ = self.lstm(x,  (h0, c0))\n",
    "        packed_out, (hn, cn) = self.lstm(x,  (h0, c0))\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        # all training example, last hidden state, all \n",
    "        # it is not last hidden state, it is the last batch\n",
    "        # print('out.squeeze() ', out.squeeze().size())\n",
    "        out = self.fc(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def train_batch(self, train_loader, optimizer, criterion):\n",
    "        # set training state to model\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        \n",
    "        with tqdm(total=len(train_loader), position=0) as progress_bar:\n",
    "            for batch_idx, (data, label) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self(data)\n",
    "                label, _ = pad_packed_sequence(label, batch_first=True)\n",
    "                # print('label: ', label.size())\n",
    "                # print('output: ', output.size())\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "    def val_batch(self, val_data, criterion): \n",
    "        # set evaluation state to the model\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "        losses = []\n",
    "        \n",
    "        class_probs = []\n",
    "        class_label = []\n",
    "        \n",
    "        # no gradient needed\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_data):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                # forward\n",
    "                scores = self(data)\n",
    "                target, _ = pad_packed_sequence(target, batch_first=True)\n",
    "                loss = criterion(scores, target)\n",
    "                # ERROR\n",
    "                losses.append(loss.cpu()) # loss for each batch\n",
    "                # save for ploting curve\n",
    "                class_probs.append(scores.squeeze(-1).cpu())\n",
    "                class_label.append(target.cpu())\n",
    "                \n",
    "        # overall loss\n",
    "        loss = np.mean(losses)\n",
    "        return loss, class_probs, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f68eb",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "675c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = BRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "# propogation of two classes\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43d059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f109dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████▌                | 3/4 [00:02<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  torch.Size([2, 378, 1])\n",
      "output:  torch.Size([2, 378, 1])\n",
      "label:  torch.Size([2, 154, 1])\n",
      "output:  torch.Size([2, 154, 1])\n",
      "label:  torch.Size([2, 559, 1])\n",
      "output:  torch.Size([2, 559, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  torch.Size([2, 817, 1])\n",
      "output:  torch.Size([2, 817, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.31it/s]\n",
      "Exception ignored in: <function _releaseLock at 0x7fc76891de60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qinqin/anaconda3/envs/py37/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 160369, 160370, 160371, 160372, 160373, 160374, 160375, 160376, 160377, 160379, 160380, 160381, 160382, 160383, 160384, 160385, 160386, 160387, 160388, 160389, 160390, 160391, 160392, 160393, 160394, 160395, 160396, 160397, 160398, 160399, 160400, 160401, 160402, 160403, 160404, 160405, 160411, 160412, 160413, 160414, 160415, 160416, 160417, 160418, 160419, 160420, 160421, 160422, 160423, 160424, 160425, 160426, 160427, 160428, 160429, 160430, 160431, 160432, 160433, 160434, 160435, 160436, 160437, 160438, 160439, 160440) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_159229/1517701223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# acc & loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_class_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_class_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_159229/2545170608.py\u001b[0m in \u001b[0;36mval_batch\u001b[0;34m(self, val_data, criterion)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# no gradient needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 160369, 160370, 160371, 160372, 160373, 160374, 160375, 160376, 160377, 160379, 160380, 160381, 160382, 160383, 160384, 160385, 160386, 160387, 160388, 160389, 160390, 160391, 160392, 160393, 160394, 160395, 160396, 160397, 160398, 160399, 160400, 160401, 160402, 160403, 160404, 160405, 160411, 160412, 160413, 160414, 160415, 160416, 160417, 160418, 160419, 160420, 160421, 160422, 160423, 160424, 160425, 160426, 160427, 160428, 160429, 160430, 160431, 160432, 160433, 160434, 160435, 160436, 160437, 160438, 160439, 160440) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate}\")\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.warning('*********************************')\n",
    "    logging.warning('epoch: ' + str(epoch))\n",
    "    logging.warning('*********************************')\n",
    "    ################\n",
    "    # 3.1. Training\n",
    "    ################\n",
    "    logging.warning('1. TRAINING:')\n",
    "    # plot pr and roc curve or not\n",
    "    plot_pr_roc = (epoch % plot_nEpoch == 0)\n",
    "\n",
    "    # training\n",
    "    model.train_batch(train_dl, optimizer, criterion)\n",
    "    \n",
    "    # acc & loss\n",
    "    train_loss, t_class_probs, t_class_label = model.val_batch(train_dl, criterion)\n",
    "    val_loss, v_class_probs, v_class_label = model.val_batch(test_dl, criterion)\n",
    "    \n",
    "    # val_accs.append(val_acc)\n",
    "    \n",
    "    print('Training: Loss:')\n",
    "    print(train_loss)\n",
    "    \n",
    "    print('VAL: Loss:')\n",
    "    print(val_loss)\n",
    "    \n",
    "    logging.warning('Training:')\n",
    "    logging.warning(f'Loss: {train_loss}')\n",
    "\n",
    "    logging.warning('Validation:')\n",
    "    logging.warning(f'Loss: {val_loss}')\n",
    "    \n",
    "    ##\n",
    "    # for tensorboard plots\n",
    "    ##\n",
    "    writer.add_scalars(\"TRAIN & VAL Loss\", {'TRAIN': train_loss, \n",
    "                                           'VAL': val_loss}, epoch)\n",
    "    \n",
    "    train_probs = torch.cat([batch.reshape(-1) for batch in t_class_probs])\n",
    "    train_label = torch.cat([lab.reshape(-1) for lab in t_class_label])\n",
    "    \n",
    "    val_probs = torch.cat([batch.reshape(-1) for batch in v_class_probs])\n",
    "    val_label = torch.cat([lab.reshape(-1) for lab in v_class_label])\n",
    "    \n",
    "    writer.add_scalars(\"AUC Score\", {'TRAIN': roc_auc_score(train_label, train_probs, average=None),\n",
    "                                    'VAL': roc_auc_score(val_label, val_probs, average=None)}, epoch)\n",
    "    \n",
    "    ##\n",
    "    # PR-curve & ROC-curve\n",
    "    ##\n",
    "    if plot_pr_roc:\n",
    "        writer.add_pr_curve(f'TRAIN: pr_curve e{epoch}', train_label, train_probs, 0)\n",
    "        writer.add_pr_curve(f'VAL: pr_curve e{epoch}', val_label, val_probs, 0)\n",
    "\n",
    "        roc_fig = rocPlot(train_label, train_probs, val_label, val_probs)\n",
    "        writer.add_figure(f'Train vs VAL: roc_curve e{epoch}', roc_fig)\n",
    "    ##\n",
    "    # Save model every m epochs\n",
    "    ##\n",
    "    if epoch % checkpoint_m == 0:\n",
    "        cPATH = f\"checkpoint/{model_name}_{epoch}.pth\"\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    }, cPATH)\n",
    "        \n",
    "logging.warning(f\"model_name: {model_name} \\n \\\n",
    "                batch_size: {batch_size} \\n \\\n",
    "                 num_epochs: {num_epochs} \\n \\\n",
    "                learning_rate: {learning_rate} \\n \")\n",
    "                # best_val_epoch: {int(np.argmax(val_accs)+1)}\") # the best val epoch\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "077e85a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4308820])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([batch.reshape(-1) for batch in t_class_probs]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59b74764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4308820])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([batch.reshape(-1) for batch in t_class_label]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e30cd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96c50fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017da9c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "seq_len = 2000\n",
    "summary(model, input_size=(1, seq_len, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cde796d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRNN(\n",
      "  (lstm): LSTM(21, 24, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=48, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dd3b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0:  torch.Size([4, 1, 24])\n",
      "c0:  torch.Size([4, 1, 24])\n",
      "out:  torch.Size([1, 2000, 48])\n",
      "hn:  torch.Size([4, 1, 24])\n",
      "cn:  torch.Size([4, 1, 24])\n",
      "out.squeeze()  torch.Size([2000, 48])\n",
      "out final:  torch.Size([2000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BRNN                                     [2000, 1]                 --\n",
       "├─LSTM: 1-1                              [1, 2000, 48]             23,232\n",
       "├─Linear: 1-2                            [2000, 1]                 49\n",
       "├─Sigmoid: 1-3                           [2000, 1]                 --\n",
       "==========================================================================================\n",
       "Total params: 23,281\n",
       "Trainable params: 23,281\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 46.56\n",
       "==========================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 0.78\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 1.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "seq_len = 2000\n",
    "summary(model, input_size=(1, seq_len, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e1a3",
   "metadata": {},
   "source": [
    "## Test pad_sequence & pack_padded_sequence & pad_packed_sequence\n",
    "### 1. pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "215728e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([[1,2,3], [2,3,4], [4,5,6]]), torch.tensor([[3,4, 5]])]\n",
    "a_pad = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)\n",
    "\n",
    "b = [torch.tensor([1,2,3]), torch.tensor([3,4])]\n",
    "b_pad = torch.nn.utils.rnn.pad_sequence(b, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ae05050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 2, 3],\n",
       "         [2, 3, 4],\n",
       "         [4, 5, 6]]),\n",
       " tensor([[3, 4, 5]])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5326aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [2, 3, 4],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[3, 4, 5],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be983fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3]), tensor([3, 4])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eba29fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28361c07",
   "metadata": {},
   "source": [
    "### pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7e37f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1, 2, 3],\n",
       "        [3, 4, 5],\n",
       "        [2, 3, 4],\n",
       "        [4, 5, 6]]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pack = torch.nn.utils.rnn.pack_padded_sequence(a_pad, batch_first=True, lengths=[3,1])\n",
    "a_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2248a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1, 3, 2, 4, 3]), batch_sizes=tensor([2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pack = torch.nn.utils.rnn.pack_padded_sequence(b_pad, batch_first=True, lengths=[3,2])\n",
    "b_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c0e28",
   "metadata": {},
   "source": [
    "### pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f2db759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [2, 3, 4],\n",
       "          [4, 5, 6]],\n",
       " \n",
       "         [[3, 4, 5],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]]),\n",
       " (tensor([[[1, 2, 3],\n",
       "           [2, 3, 4],\n",
       "           [4, 5, 6]],\n",
       "  \n",
       "          [[3, 4, 5],\n",
       "           [0, 0, 0],\n",
       "           [0, 0, 0]]]),\n",
       "  tensor([3, 1])))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_reverse_pack = torch.nn.utils.rnn.pad_packed_sequence(a_pack, batch_first=True)\n",
    "a_pad, a_reverse_pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89b69d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [3, 4, 0]]),\n",
       " (tensor([[1, 2, 3],\n",
       "          [3, 4, 0]]),\n",
       "  tensor([3, 2])))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reverse_pack = torch.nn.utils.rnn.pad_packed_sequence(b_pack, batch_first=True)\n",
    "b_pad, b_reverse_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cabbc",
   "metadata": {},
   "source": [
    "## Note\n",
    "### 1. pad_sequence does not sort sequence by seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da6a34df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "c = [torch.ones(5, 10), torch.ones(7, 10), torch.ones(3, 10)]\n",
    "c_pad = pad_sequence(c, batch_first=True)\n",
    "c_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb2856",
   "metadata": {},
   "source": [
    "### 2. but pack_padded_sequence wants a sorted pad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7b38d41",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_299729/436231044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc_pack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability."
     ]
    }
   ],
   "source": [
    "c_pack = torch.nn.utils.rnn.pack_padded_sequence(c_pad, batch_first=True, lengths=[5,7,3])\n",
    "c_pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516eaca",
   "metadata": {},
   "source": [
    "### 3. set enforce_sorted=False or padding manuly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db919780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), batch_sizes=tensor([3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([1, 0, 2]), unsorted_indices=tensor([1, 0, 2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_pack = torch.nn.utils.rnn.pack_padded_sequence(c_pad, batch_first=True, lengths=[5,7,3], enforce_sorted=False)\n",
    "c_pack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429284b",
   "metadata": {},
   "source": [
    "### 4. sorted_indices & unsorted_indices are not none only if enforce_sorted=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8728333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a1546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65771a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad48b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
